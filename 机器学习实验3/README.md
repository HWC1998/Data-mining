# 组员信息
**洪伟程（组长）**
**苏聪颖**
## 分工：
### 实验三：
洪伟程负责完成**PCA算法**

苏聪颖完成**K-Means算法**

# 实验三  《k-means聚类算法》

## **题目**

用C++实现k-means聚类算法，

1. 对实验二中的z-score归一化的成绩数据进行测试，观察聚类为2类，3类，4类，5类的结果，观察得出什么结论？
2. 由老师给出测试数据，进行测试，并画出可视化出散点图，类中心，类半径，并分析聚为几类合适。

样例数据(x,y)数据对：



| 3.45 | 7.08 |
| ---- | ---- |
| 1.76 | 7.24 |
| 4.29 | 9.55 |
| 3.35 | 6.65 |
| 3.17 | 6.41 |
| 3.68 | 5.99 |
| 2.11 | 4.08 |
| 2.58 | 7.10 |
| 3.45 | 7.88 |
| 6.17 | 5.40 |
| 4.20 | 6.46 |
| 5.87 | 3.87 |
| 5.47 | 2.21 |
| 5.97 | 3.62 |
| 6.24 | 3.06 |
| 6.89 | 2.41 |
| 5.38 | 2.32 |
| 5.13 | 2.73 |
| 7.26 | 4.19 |
| 6.32 | 3.62 |

找到聚类中心后，判断(2,6)是属于哪一类？

## 说明

**可视化结果说明**

本次的可视化.py代码由（软件183 陈培佳 1806300088）提供，我方提供当聚类为2类，3类，4类，5类（本实验的第一题和第二题）时，质心和簇样本的相应聚类的每个txt文件（一共8个txt文件），陈培佳同学帮忙将每个文件对应地可视化。感谢！！！



**第一题数据文件来源**

实验二中的z-score归一化的成绩数据并命名为1_data.txt



**第二题数据文件来源**

题目中的数据，记录在2_data.txt



**实验第一题的回答**

根据聚类为2类，3类，4类，5类的可视化结果显示，在开始使用K-Means算法的时候，簇的质心的选取显得非常重要。与在聚类为5的时候，出现了一个点就是质心，也一个簇。同时聚类为4类，5类的时候，质心的变化也不大，同时出现一个簇质心（红色的质心）没有发生变动。但是如果改变了簇的质心选取，那些每个的聚类的质心也会发生更改，对应的簇中的点也会发生变动。



**实验第二题的回答**

聚类为：2

0簇的质心为：3.19362 6.84676 该类半径为：2.9714

1簇的质心为：6.06621 3.3393  该类半径为：2.06332

(2, 6)是属于0类



聚类为：3

0簇的质心为：5.90405 2.9705 该类半径为：1.13413

1簇的质心为：3.19362 6.84676 该类半径为：2.9714

2簇的质心为：6.606 4.916  该类半径为：0.977135

(2, 6)是属于1类



聚类为：4
0簇的质心为：2.89762 7.16164 该类半径为：1.14032
1簇的质心为：6.06621 3.3393 该类半径为：2.06332
2簇的质心为：4.29 9.55 该类半径为：0
3簇的质心为：3.24765 5.71975 该类半径为：1.99575
(2, 6)是属于3类



聚类为：5
0簇的质心为：3.27431 5.91515 该类半径为：2.17333
1簇的质心为：2.088 7.184 该类半径为：0.499119
2簇的质心为：3.74217 8.14783 该类半径为：1.50539
3簇的质心为：6.30819 4.16579 该类半径为：1.24193
4簇的质心为：5.85426 2.54024 该类半径为：1.0439
(2, 6)是属于1类



因为样本较少，根据样本可视化散点图显示，当聚类变大的时候，每个簇的点开始变少。当聚类为2的时候，样本的数据呈现两极化，简单明白，当簇为5的时候，每个簇可分配到的点在可视化散点图中显得比较平均。因此我认为此时聚类为2或者为5比较合适。然而在聚类为4的时候出现一个点为簇的质心和整个簇，我觉得此时是不合适的。而聚类为3的时候，簇的可分配到的点在可视化散点图中显得不够平均，比较地不美观，因此我觉得聚类为3不够合适。



**实验第一题使用的库函数及思路：**

    include <iostream>
    include <fstream>
    include <Eigen/Dense>//需要下载Eigen库函数，用于计算得到特征值和特征向量
    include <Eigen/Eigenvalues>//需要下载Eigen库函数，用于计算得到特征值和特征向量



主要方法为PCA降维和K－Means算法：

1、定义存储初始样本数据的数组，读取初始样本数据，为P[]；

2、定义存储初始样本数据的转置数组数组，为PT[]

3、定义一个数组存放协方差矩阵，为C[],计算方法为：

     int i0 = 0;//协方差矩阵的行
    
     int j0 = 0;//协方差矩阵的列
    
     for (int a = 0; a < VOL; a++)//转置矩阵的行
    
     {
    
     
    
    	​for (int b = 0; b < VOL; b++)//未转置矩阵的列
    
    ​	{
    
    ​  	for (int c = 0; c < ROW;)//转置矩阵的列
    
    ​  	{
    
    ​		for (int d = 0; d < ROW;)//未转置矩阵的行
    
    ​		{
    
    ​  		C[i0][j0] += PT[a][c] * P[d][b];
    
    ​  		c++;
    
    ​  		d++;
    
    ​		}
    
    ​  	}
    	
    ​  	C[i0][j0] = C[i0][j0] / ROW;
    
    ​  	j0++;
    
    ​	}
    
    ​	if (j0 == 9)//重置协方差矩阵的列的位置，并且换行
    
    	​{
    
    ​  	j0 = 0;
    
    ​  	i0++;
    
    	​}
    
     
    
    }

4、定义数组cv[]存放特征值、cv2[]存放最大的特征值对应的下标，fv1[]数组存放特征向量,fv[][]数组存放最大的两个特征值对应的特征向量。主要表现为：

 用库函数计算所有的特征值，然后排序，找出最大的两个特征值，接着记录这两个特征值对应的特征向量。

5、计算得到降到2维之后的数据，用Tddm[][]数组存储：

     int i1 = 0;//二维数据矩阵Tddm的行
    
     int j1 = 0;//二维数据矩阵Tddm的列
    
     for (int a = 0; a < 2; a++)//fv2矩阵的行
    
     {
    
     
    
    ​	for (int b = 0; b < ROW; b++)//转置矩阵的列
    
    ​	{
    
    ​  	for (int c = 0; c < 10;)//fv2矩阵的列
    
    ​  	{
    
    		​for (int d = 0; d < 10;)//转置矩阵的行
    
    ​		{
    
    ​  		Tddm[i1][j1] += fv2[a][c] * PT[d][b];
    
    ​  		c++;
    	
    ​  		d++;
    
    ​		}
    
    ​  	}
    
    ​  	j1++;
    
     	}
    
    ​	if (j1 == ROW - 1)
    
    	{
    
    ​  	j1 = 0;
    
    ​  	i1++;
    
    	​}
    
    }

5、从降维之后的数据根据需要的聚类随机选取质心，比如聚类为2，随机选取两个作为质心，然后进行K-Means算法：



    void Findmin(int index, int a)//判断数据距离质心的距离，因为距离的平方越大，距离也就越大，因此这里不开平方
    
    {
    
      for (int i = 0; i < a; i++)//数据距离质心的距离
    
      {
    
    	​kdistance[i] = (Tddm[0][index] - kk[i][0]) * (Tddm[0][index] - kk[i][0]) + (Tddm[1][index] - kk[i][1]) * (Tddm[1][index] - kk[i][1]);
    
      }
    
      int temp = 0;
    
      for (int i = 0; i < a; i++)
    
      {
    
    	​if (kdistance[temp] > kdistance[i])
    
    	​{
    
    ​  		temp = i;
    
    ​	}
    
      }
    
      Tddm2[index] = temp;   //划定簇
	}

    void update(int a)//质心更新
    
    {
    
      int count = 1;
    
      int s = Tddm2[a];//获取簇
    
      for (int i = 0; i <= a; i++)
    
      {
    
    ​	if (Tddm2[i] == s)//判断样本属于哪个簇
    
    	{
    
    ​  	kk[s][0] += Tddm[0][i];
    
    ​  	kk[s][1] += Tddm[1][i];
    
    ​  	count++;
    
    ​	}
    
      }
    
      	//更新
    
      	kk[s][0] = kk[s][0] / count;
    
      	kk[s][1] = kk[s][1] / count;
    
    }

    void Cluster(int a)//划分样本到簇
    
    {
    
      cout << "聚类为" << a << "类时：" << endl;
    
      int over = 0;//定义变量over,判断样本的簇已经划分好了，是否还需要发生变动
    
      while (over == 0)
    
      {
    
    ​	for (int i = 0; i < a; i++)
    
    ​	{
    
    ​  	kk2[i][0] = kk[i][0];
    
    ​  	kk2[i][1] = kk[i][1];
    
    ​	}
    
    ​	for (int i = 0; i < 106; i++)
    
    ​	{
    
    ​  	Findmin(i, a);//找出距离离点最近的质心
    
    ​  	update(i);//质心更新
    
    	​}
    
    ​	over = 1;
    
    ​	for (int i = 0; i < a; i++)
    
    ​	{
    
    ​  	if ((kk2[i][0] != kk[i][0]) || (kk2[i][1] != kk[i][1]))//如果簇的质心发生更改
    
    ​  	{
    
    ​		over = 0;
    
    ​  	}
    
    ​	}
    
      }
    
    }

６、读取已经划分簇的样本，画出可视化散点图。









**实验第二题使用的库函数及思路：**

    include <iostream>
    include <fstream>
    include<cmath>

主要方法为K－Means算法：

１、直接K－Means算法划分样本到簇（方法如同实验的第一题）

２、读取已经划分簇的样本，画出可视化散点图。

３、判断(2, 6)是属于哪一类，函数如下：

    void classification(int a)//判断(2, 6)是属于哪一类
    {
    	for (int i = 0; i < a; i++)//数据距离质心的距离
    	{
    		kdistance[i] = (2 - kk[i][0]) * (2 - kk[i][0]) + (6 - kk[i][1]) * (6 - kk[i][1]);
    	}
    	int temp = 0;
    	for (int i = 0; i < a; i++)
    	{
    		if (kdistance[temp] > kdistance[i])
    		{
    			temp = i;
    		}
    	}
    	for (int i = 0; i < a; i++)//输出簇的质心
    	{
    		cout << i << "簇的质心为：" << kk[i][0] << " " << kk[i][1] << endl;
    	}
    	cout<<"(2, 6)是属于"<<temp<<"类"<<endl; //划定簇
    	cout << endl;
    }

## 难题与解决

主要难题为PCA降维，一开始还是挺迷迷糊糊，后来通过网上查阅资料——【机器学习】降维——PCA（非常详细）https://zhuanlan.zhihu.com/p/77151308
通过仔细读懂计算，便可以解决这个问题，其中使用了相应的ｔｘｔ文件去存储协方差矩阵、特征值和特征向量去进行过渡。最后K－Means算法给样本划分簇的时候使用数组标记就非常简单了。



## 总结

一开始实验的时候觉得是挺难的，迟迟不肯动手去操作，后来仔细地阅读网上的资料，就明白了大致的流程，在使用算法计算完协方差矩阵之后，其他的算法基本类似，也就不算很难了。
本次的可视化.py代码由**陈培佳同学**提供，我方提供当聚类为2类，3类，4类，5类（本实验的第一题和第二题）时，质心和簇样本的相应聚类的每个txt文件（一共8个txt文件），**陈培佳同学**帮忙将每个文件对应地可视化，感谢！！！















